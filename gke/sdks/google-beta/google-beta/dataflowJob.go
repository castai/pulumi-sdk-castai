// Code generated by pulumi-language-go DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package googlebeta

import (
	"context"
	"reflect"

	"errors"
	"github.com/pulumi/pulumi-terraform-provider/sdks/go/google-beta/v6/google-beta/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

type DataflowJob struct {
	pulumi.CustomResourceState

	// List of experiments that should be used by the job. An example value is ["enable_stackdriver_agent_metrics"].
	AdditionalExperiments pulumi.StringArrayOutput `pulumi:"additionalExperiments"`
	DataflowJobId         pulumi.StringOutput      `pulumi:"dataflowJobId"`
	EffectiveLabels       pulumi.StringMapOutput   `pulumi:"effectiveLabels"`
	// Indicates if the job should use the streaming engine feature.
	EnableStreamingEngine pulumi.BoolPtrOutput `pulumi:"enableStreamingEngine"`
	// The configuration for VM IPs. Options are "WORKER_IP_PUBLIC" or "WORKER_IP_PRIVATE".
	IpConfiguration pulumi.StringPtrOutput `pulumi:"ipConfiguration"`
	// The unique ID of this job.
	JobId pulumi.StringOutput `pulumi:"jobId"`
	// The name for the Cloud KMS key for the job. Key format is:
	// projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY
	KmsKeyName pulumi.StringPtrOutput `pulumi:"kmsKeyName"`
	// User labels to be specified for the job. Keys and values should follow the restrictions specified in the labeling
	// restrictions page. NOTE: This field is non-authoritative, and will only manage the labels present in your configuration.
	// Please refer to the field 'effective_labels' for all of the labels present on the resource.
	Labels pulumi.StringMapOutput `pulumi:"labels"`
	// The machine type to use for the job.
	MachineType pulumi.StringPtrOutput `pulumi:"machineType"`
	// The number of workers permitted to work on the job. More workers may improve processing speed at additional cost.
	MaxWorkers pulumi.Float64PtrOutput `pulumi:"maxWorkers"`
	// A unique name for the resource, required by Dataflow.
	Name pulumi.StringOutput `pulumi:"name"`
	// The network to which VMs will be assigned. If it is not provided, "default" will be used.
	Network  pulumi.StringPtrOutput `pulumi:"network"`
	OnDelete pulumi.StringPtrOutput `pulumi:"onDelete"`
	// Key/Value pairs to be passed to the Dataflow job (as used in the template).
	Parameters pulumi.StringMapOutput `pulumi:"parameters"`
	// The project in which the resource belongs.
	Project pulumi.StringOutput `pulumi:"project"`
	// The region in which the created job should run.
	Region pulumi.StringPtrOutput `pulumi:"region"`
	// The Service Account email used to create the job.
	ServiceAccountEmail      pulumi.StringPtrOutput `pulumi:"serviceAccountEmail"`
	SkipWaitOnJobTermination pulumi.BoolPtrOutput   `pulumi:"skipWaitOnJobTermination"`
	// The current state of the resource, selected from the JobState enum.
	State pulumi.StringOutput `pulumi:"state"`
	// The subnetwork to which VMs will be assigned. Should be of the form "regions/REGION/subnetworks/SUBNETWORK".
	Subnetwork pulumi.StringPtrOutput `pulumi:"subnetwork"`
	// A writeable location on Google Cloud Storage for the Dataflow job to dump its temporary data.
	TempGcsLocation pulumi.StringOutput `pulumi:"tempGcsLocation"`
	// The Google Cloud Storage path to the Dataflow job template.
	TemplateGcsPath pulumi.StringOutput `pulumi:"templateGcsPath"`
	// The combination of labels configured directly on the resource and default labels configured on the provider.
	TerraformLabels pulumi.StringMapOutput       `pulumi:"terraformLabels"`
	Timeouts        DataflowJobTimeoutsPtrOutput `pulumi:"timeouts"`
	// Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the
	// corresponding name prefixes of the new job.
	TransformNameMapping pulumi.StringMapOutput `pulumi:"transformNameMapping"`
	// The type of this job, selected from the JobType enum.
	Type pulumi.StringOutput `pulumi:"type"`
	// The zone in which the created job should run. If it is not provided, the provider zone is used.
	Zone pulumi.StringPtrOutput `pulumi:"zone"`
}

// NewDataflowJob registers a new resource with the given unique name, arguments, and options.
func NewDataflowJob(ctx *pulumi.Context,
	name string, args *DataflowJobArgs, opts ...pulumi.ResourceOption) (*DataflowJob, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.TempGcsLocation == nil {
		return nil, errors.New("invalid value for required argument 'TempGcsLocation'")
	}
	if args.TemplateGcsPath == nil {
		return nil, errors.New("invalid value for required argument 'TemplateGcsPath'")
	}
	opts = internal.PkgResourceDefaultOpts(opts)
	ref, err := internal.PkgGetPackageRef(ctx)
	if err != nil {
		return nil, err
	}
	var resource DataflowJob
	err = ctx.RegisterPackageResource("google-beta:index/dataflowJob:DataflowJob", name, args, &resource, ref, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetDataflowJob gets an existing DataflowJob resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetDataflowJob(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *DataflowJobState, opts ...pulumi.ResourceOption) (*DataflowJob, error) {
	var resource DataflowJob
	ref, err := internal.PkgGetPackageRef(ctx)
	if err != nil {
		return nil, err
	}
	err = ctx.ReadPackageResource("google-beta:index/dataflowJob:DataflowJob", name, id, state, &resource, ref, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering DataflowJob resources.
type dataflowJobState struct {
	// List of experiments that should be used by the job. An example value is ["enable_stackdriver_agent_metrics"].
	AdditionalExperiments []string          `pulumi:"additionalExperiments"`
	DataflowJobId         *string           `pulumi:"dataflowJobId"`
	EffectiveLabels       map[string]string `pulumi:"effectiveLabels"`
	// Indicates if the job should use the streaming engine feature.
	EnableStreamingEngine *bool `pulumi:"enableStreamingEngine"`
	// The configuration for VM IPs. Options are "WORKER_IP_PUBLIC" or "WORKER_IP_PRIVATE".
	IpConfiguration *string `pulumi:"ipConfiguration"`
	// The unique ID of this job.
	JobId *string `pulumi:"jobId"`
	// The name for the Cloud KMS key for the job. Key format is:
	// projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY
	KmsKeyName *string `pulumi:"kmsKeyName"`
	// User labels to be specified for the job. Keys and values should follow the restrictions specified in the labeling
	// restrictions page. NOTE: This field is non-authoritative, and will only manage the labels present in your configuration.
	// Please refer to the field 'effective_labels' for all of the labels present on the resource.
	Labels map[string]string `pulumi:"labels"`
	// The machine type to use for the job.
	MachineType *string `pulumi:"machineType"`
	// The number of workers permitted to work on the job. More workers may improve processing speed at additional cost.
	MaxWorkers *float64 `pulumi:"maxWorkers"`
	// A unique name for the resource, required by Dataflow.
	Name *string `pulumi:"name"`
	// The network to which VMs will be assigned. If it is not provided, "default" will be used.
	Network  *string `pulumi:"network"`
	OnDelete *string `pulumi:"onDelete"`
	// Key/Value pairs to be passed to the Dataflow job (as used in the template).
	Parameters map[string]string `pulumi:"parameters"`
	// The project in which the resource belongs.
	Project *string `pulumi:"project"`
	// The region in which the created job should run.
	Region *string `pulumi:"region"`
	// The Service Account email used to create the job.
	ServiceAccountEmail      *string `pulumi:"serviceAccountEmail"`
	SkipWaitOnJobTermination *bool   `pulumi:"skipWaitOnJobTermination"`
	// The current state of the resource, selected from the JobState enum.
	State *string `pulumi:"state"`
	// The subnetwork to which VMs will be assigned. Should be of the form "regions/REGION/subnetworks/SUBNETWORK".
	Subnetwork *string `pulumi:"subnetwork"`
	// A writeable location on Google Cloud Storage for the Dataflow job to dump its temporary data.
	TempGcsLocation *string `pulumi:"tempGcsLocation"`
	// The Google Cloud Storage path to the Dataflow job template.
	TemplateGcsPath *string `pulumi:"templateGcsPath"`
	// The combination of labels configured directly on the resource and default labels configured on the provider.
	TerraformLabels map[string]string    `pulumi:"terraformLabels"`
	Timeouts        *DataflowJobTimeouts `pulumi:"timeouts"`
	// Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the
	// corresponding name prefixes of the new job.
	TransformNameMapping map[string]string `pulumi:"transformNameMapping"`
	// The type of this job, selected from the JobType enum.
	Type *string `pulumi:"type"`
	// The zone in which the created job should run. If it is not provided, the provider zone is used.
	Zone *string `pulumi:"zone"`
}

type DataflowJobState struct {
	// List of experiments that should be used by the job. An example value is ["enable_stackdriver_agent_metrics"].
	AdditionalExperiments pulumi.StringArrayInput
	DataflowJobId         pulumi.StringPtrInput
	EffectiveLabels       pulumi.StringMapInput
	// Indicates if the job should use the streaming engine feature.
	EnableStreamingEngine pulumi.BoolPtrInput
	// The configuration for VM IPs. Options are "WORKER_IP_PUBLIC" or "WORKER_IP_PRIVATE".
	IpConfiguration pulumi.StringPtrInput
	// The unique ID of this job.
	JobId pulumi.StringPtrInput
	// The name for the Cloud KMS key for the job. Key format is:
	// projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY
	KmsKeyName pulumi.StringPtrInput
	// User labels to be specified for the job. Keys and values should follow the restrictions specified in the labeling
	// restrictions page. NOTE: This field is non-authoritative, and will only manage the labels present in your configuration.
	// Please refer to the field 'effective_labels' for all of the labels present on the resource.
	Labels pulumi.StringMapInput
	// The machine type to use for the job.
	MachineType pulumi.StringPtrInput
	// The number of workers permitted to work on the job. More workers may improve processing speed at additional cost.
	MaxWorkers pulumi.Float64PtrInput
	// A unique name for the resource, required by Dataflow.
	Name pulumi.StringPtrInput
	// The network to which VMs will be assigned. If it is not provided, "default" will be used.
	Network  pulumi.StringPtrInput
	OnDelete pulumi.StringPtrInput
	// Key/Value pairs to be passed to the Dataflow job (as used in the template).
	Parameters pulumi.StringMapInput
	// The project in which the resource belongs.
	Project pulumi.StringPtrInput
	// The region in which the created job should run.
	Region pulumi.StringPtrInput
	// The Service Account email used to create the job.
	ServiceAccountEmail      pulumi.StringPtrInput
	SkipWaitOnJobTermination pulumi.BoolPtrInput
	// The current state of the resource, selected from the JobState enum.
	State pulumi.StringPtrInput
	// The subnetwork to which VMs will be assigned. Should be of the form "regions/REGION/subnetworks/SUBNETWORK".
	Subnetwork pulumi.StringPtrInput
	// A writeable location on Google Cloud Storage for the Dataflow job to dump its temporary data.
	TempGcsLocation pulumi.StringPtrInput
	// The Google Cloud Storage path to the Dataflow job template.
	TemplateGcsPath pulumi.StringPtrInput
	// The combination of labels configured directly on the resource and default labels configured on the provider.
	TerraformLabels pulumi.StringMapInput
	Timeouts        DataflowJobTimeoutsPtrInput
	// Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the
	// corresponding name prefixes of the new job.
	TransformNameMapping pulumi.StringMapInput
	// The type of this job, selected from the JobType enum.
	Type pulumi.StringPtrInput
	// The zone in which the created job should run. If it is not provided, the provider zone is used.
	Zone pulumi.StringPtrInput
}

func (DataflowJobState) ElementType() reflect.Type {
	return reflect.TypeOf((*dataflowJobState)(nil)).Elem()
}

type dataflowJobArgs struct {
	// List of experiments that should be used by the job. An example value is ["enable_stackdriver_agent_metrics"].
	AdditionalExperiments []string `pulumi:"additionalExperiments"`
	DataflowJobId         *string  `pulumi:"dataflowJobId"`
	// Indicates if the job should use the streaming engine feature.
	EnableStreamingEngine *bool `pulumi:"enableStreamingEngine"`
	// The configuration for VM IPs. Options are "WORKER_IP_PUBLIC" or "WORKER_IP_PRIVATE".
	IpConfiguration *string `pulumi:"ipConfiguration"`
	// The name for the Cloud KMS key for the job. Key format is:
	// projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY
	KmsKeyName *string `pulumi:"kmsKeyName"`
	// User labels to be specified for the job. Keys and values should follow the restrictions specified in the labeling
	// restrictions page. NOTE: This field is non-authoritative, and will only manage the labels present in your configuration.
	// Please refer to the field 'effective_labels' for all of the labels present on the resource.
	Labels map[string]string `pulumi:"labels"`
	// The machine type to use for the job.
	MachineType *string `pulumi:"machineType"`
	// The number of workers permitted to work on the job. More workers may improve processing speed at additional cost.
	MaxWorkers *float64 `pulumi:"maxWorkers"`
	// A unique name for the resource, required by Dataflow.
	Name *string `pulumi:"name"`
	// The network to which VMs will be assigned. If it is not provided, "default" will be used.
	Network  *string `pulumi:"network"`
	OnDelete *string `pulumi:"onDelete"`
	// Key/Value pairs to be passed to the Dataflow job (as used in the template).
	Parameters map[string]string `pulumi:"parameters"`
	// The project in which the resource belongs.
	Project *string `pulumi:"project"`
	// The region in which the created job should run.
	Region *string `pulumi:"region"`
	// The Service Account email used to create the job.
	ServiceAccountEmail      *string `pulumi:"serviceAccountEmail"`
	SkipWaitOnJobTermination *bool   `pulumi:"skipWaitOnJobTermination"`
	// The subnetwork to which VMs will be assigned. Should be of the form "regions/REGION/subnetworks/SUBNETWORK".
	Subnetwork *string `pulumi:"subnetwork"`
	// A writeable location on Google Cloud Storage for the Dataflow job to dump its temporary data.
	TempGcsLocation string `pulumi:"tempGcsLocation"`
	// The Google Cloud Storage path to the Dataflow job template.
	TemplateGcsPath string               `pulumi:"templateGcsPath"`
	Timeouts        *DataflowJobTimeouts `pulumi:"timeouts"`
	// Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the
	// corresponding name prefixes of the new job.
	TransformNameMapping map[string]string `pulumi:"transformNameMapping"`
	// The zone in which the created job should run. If it is not provided, the provider zone is used.
	Zone *string `pulumi:"zone"`
}

// The set of arguments for constructing a DataflowJob resource.
type DataflowJobArgs struct {
	// List of experiments that should be used by the job. An example value is ["enable_stackdriver_agent_metrics"].
	AdditionalExperiments pulumi.StringArrayInput
	DataflowJobId         pulumi.StringPtrInput
	// Indicates if the job should use the streaming engine feature.
	EnableStreamingEngine pulumi.BoolPtrInput
	// The configuration for VM IPs. Options are "WORKER_IP_PUBLIC" or "WORKER_IP_PRIVATE".
	IpConfiguration pulumi.StringPtrInput
	// The name for the Cloud KMS key for the job. Key format is:
	// projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY
	KmsKeyName pulumi.StringPtrInput
	// User labels to be specified for the job. Keys and values should follow the restrictions specified in the labeling
	// restrictions page. NOTE: This field is non-authoritative, and will only manage the labels present in your configuration.
	// Please refer to the field 'effective_labels' for all of the labels present on the resource.
	Labels pulumi.StringMapInput
	// The machine type to use for the job.
	MachineType pulumi.StringPtrInput
	// The number of workers permitted to work on the job. More workers may improve processing speed at additional cost.
	MaxWorkers pulumi.Float64PtrInput
	// A unique name for the resource, required by Dataflow.
	Name pulumi.StringPtrInput
	// The network to which VMs will be assigned. If it is not provided, "default" will be used.
	Network  pulumi.StringPtrInput
	OnDelete pulumi.StringPtrInput
	// Key/Value pairs to be passed to the Dataflow job (as used in the template).
	Parameters pulumi.StringMapInput
	// The project in which the resource belongs.
	Project pulumi.StringPtrInput
	// The region in which the created job should run.
	Region pulumi.StringPtrInput
	// The Service Account email used to create the job.
	ServiceAccountEmail      pulumi.StringPtrInput
	SkipWaitOnJobTermination pulumi.BoolPtrInput
	// The subnetwork to which VMs will be assigned. Should be of the form "regions/REGION/subnetworks/SUBNETWORK".
	Subnetwork pulumi.StringPtrInput
	// A writeable location on Google Cloud Storage for the Dataflow job to dump its temporary data.
	TempGcsLocation pulumi.StringInput
	// The Google Cloud Storage path to the Dataflow job template.
	TemplateGcsPath pulumi.StringInput
	Timeouts        DataflowJobTimeoutsPtrInput
	// Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the
	// corresponding name prefixes of the new job.
	TransformNameMapping pulumi.StringMapInput
	// The zone in which the created job should run. If it is not provided, the provider zone is used.
	Zone pulumi.StringPtrInput
}

func (DataflowJobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*dataflowJobArgs)(nil)).Elem()
}

type DataflowJobInput interface {
	pulumi.Input

	ToDataflowJobOutput() DataflowJobOutput
	ToDataflowJobOutputWithContext(ctx context.Context) DataflowJobOutput
}

func (*DataflowJob) ElementType() reflect.Type {
	return reflect.TypeOf((**DataflowJob)(nil)).Elem()
}

func (i *DataflowJob) ToDataflowJobOutput() DataflowJobOutput {
	return i.ToDataflowJobOutputWithContext(context.Background())
}

func (i *DataflowJob) ToDataflowJobOutputWithContext(ctx context.Context) DataflowJobOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DataflowJobOutput)
}

type DataflowJobOutput struct{ *pulumi.OutputState }

func (DataflowJobOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**DataflowJob)(nil)).Elem()
}

func (o DataflowJobOutput) ToDataflowJobOutput() DataflowJobOutput {
	return o
}

func (o DataflowJobOutput) ToDataflowJobOutputWithContext(ctx context.Context) DataflowJobOutput {
	return o
}

// List of experiments that should be used by the job. An example value is ["enable_stackdriver_agent_metrics"].
func (o DataflowJobOutput) AdditionalExperiments() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringArrayOutput { return v.AdditionalExperiments }).(pulumi.StringArrayOutput)
}

func (o DataflowJobOutput) DataflowJobId() pulumi.StringOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringOutput { return v.DataflowJobId }).(pulumi.StringOutput)
}

func (o DataflowJobOutput) EffectiveLabels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringMapOutput { return v.EffectiveLabels }).(pulumi.StringMapOutput)
}

// Indicates if the job should use the streaming engine feature.
func (o DataflowJobOutput) EnableStreamingEngine() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.BoolPtrOutput { return v.EnableStreamingEngine }).(pulumi.BoolPtrOutput)
}

// The configuration for VM IPs. Options are "WORKER_IP_PUBLIC" or "WORKER_IP_PRIVATE".
func (o DataflowJobOutput) IpConfiguration() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringPtrOutput { return v.IpConfiguration }).(pulumi.StringPtrOutput)
}

// The unique ID of this job.
func (o DataflowJobOutput) JobId() pulumi.StringOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringOutput { return v.JobId }).(pulumi.StringOutput)
}

// The name for the Cloud KMS key for the job. Key format is:
// projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY
func (o DataflowJobOutput) KmsKeyName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringPtrOutput { return v.KmsKeyName }).(pulumi.StringPtrOutput)
}

// User labels to be specified for the job. Keys and values should follow the restrictions specified in the labeling
// restrictions page. NOTE: This field is non-authoritative, and will only manage the labels present in your configuration.
// Please refer to the field 'effective_labels' for all of the labels present on the resource.
func (o DataflowJobOutput) Labels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringMapOutput { return v.Labels }).(pulumi.StringMapOutput)
}

// The machine type to use for the job.
func (o DataflowJobOutput) MachineType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringPtrOutput { return v.MachineType }).(pulumi.StringPtrOutput)
}

// The number of workers permitted to work on the job. More workers may improve processing speed at additional cost.
func (o DataflowJobOutput) MaxWorkers() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.Float64PtrOutput { return v.MaxWorkers }).(pulumi.Float64PtrOutput)
}

// A unique name for the resource, required by Dataflow.
func (o DataflowJobOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

// The network to which VMs will be assigned. If it is not provided, "default" will be used.
func (o DataflowJobOutput) Network() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringPtrOutput { return v.Network }).(pulumi.StringPtrOutput)
}

func (o DataflowJobOutput) OnDelete() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringPtrOutput { return v.OnDelete }).(pulumi.StringPtrOutput)
}

// Key/Value pairs to be passed to the Dataflow job (as used in the template).
func (o DataflowJobOutput) Parameters() pulumi.StringMapOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringMapOutput { return v.Parameters }).(pulumi.StringMapOutput)
}

// The project in which the resource belongs.
func (o DataflowJobOutput) Project() pulumi.StringOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringOutput { return v.Project }).(pulumi.StringOutput)
}

// The region in which the created job should run.
func (o DataflowJobOutput) Region() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringPtrOutput { return v.Region }).(pulumi.StringPtrOutput)
}

// The Service Account email used to create the job.
func (o DataflowJobOutput) ServiceAccountEmail() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringPtrOutput { return v.ServiceAccountEmail }).(pulumi.StringPtrOutput)
}

func (o DataflowJobOutput) SkipWaitOnJobTermination() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.BoolPtrOutput { return v.SkipWaitOnJobTermination }).(pulumi.BoolPtrOutput)
}

// The current state of the resource, selected from the JobState enum.
func (o DataflowJobOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringOutput { return v.State }).(pulumi.StringOutput)
}

// The subnetwork to which VMs will be assigned. Should be of the form "regions/REGION/subnetworks/SUBNETWORK".
func (o DataflowJobOutput) Subnetwork() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringPtrOutput { return v.Subnetwork }).(pulumi.StringPtrOutput)
}

// A writeable location on Google Cloud Storage for the Dataflow job to dump its temporary data.
func (o DataflowJobOutput) TempGcsLocation() pulumi.StringOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringOutput { return v.TempGcsLocation }).(pulumi.StringOutput)
}

// The Google Cloud Storage path to the Dataflow job template.
func (o DataflowJobOutput) TemplateGcsPath() pulumi.StringOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringOutput { return v.TemplateGcsPath }).(pulumi.StringOutput)
}

// The combination of labels configured directly on the resource and default labels configured on the provider.
func (o DataflowJobOutput) TerraformLabels() pulumi.StringMapOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringMapOutput { return v.TerraformLabels }).(pulumi.StringMapOutput)
}

func (o DataflowJobOutput) Timeouts() DataflowJobTimeoutsPtrOutput {
	return o.ApplyT(func(v *DataflowJob) DataflowJobTimeoutsPtrOutput { return v.Timeouts }).(DataflowJobTimeoutsPtrOutput)
}

// Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the
// corresponding name prefixes of the new job.
func (o DataflowJobOutput) TransformNameMapping() pulumi.StringMapOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringMapOutput { return v.TransformNameMapping }).(pulumi.StringMapOutput)
}

// The type of this job, selected from the JobType enum.
func (o DataflowJobOutput) Type() pulumi.StringOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringOutput { return v.Type }).(pulumi.StringOutput)
}

// The zone in which the created job should run. If it is not provided, the provider zone is used.
func (o DataflowJobOutput) Zone() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataflowJob) pulumi.StringPtrOutput { return v.Zone }).(pulumi.StringPtrOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*DataflowJobInput)(nil)).Elem(), &DataflowJob{})
	pulumi.RegisterOutputType(DataflowJobOutput{})
}
