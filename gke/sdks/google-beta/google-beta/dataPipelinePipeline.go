// Code generated by pulumi-language-go DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package googlebeta

import (
	"context"
	"reflect"

	"errors"
	"github.com/pulumi/pulumi-terraform-provider/sdks/go/google-beta/v6/google-beta/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

type DataPipelinePipeline struct {
	pulumi.CustomResourceState

	// The timestamp when the pipeline was initially created. Set by the Data Pipelines service. A timestamp in RFC3339 UTC
	// "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and
	// "2014-10-02T15:01:23.045123456Z".
	CreateTime             pulumi.StringOutput `pulumi:"createTime"`
	DataPipelinePipelineId pulumi.StringOutput `pulumi:"dataPipelinePipelineId"`
	// The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores
	// (_).
	DisplayName pulumi.StringPtrOutput `pulumi:"displayName"`
	// Number of jobs.
	JobCount pulumi.Float64Output `pulumi:"jobCount"`
	// The timestamp when the pipeline was last modified. Set by the Data Pipelines service. A timestamp in RFC3339 UTC "Zulu"
	// format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and
	// "2014-10-02T15:01:23.045123456Z".
	LastUpdateTime pulumi.StringOutput `pulumi:"lastUpdateTime"`
	// "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID." "- PROJECT_ID can
	// contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see
	// Identifying projects." "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can
	// be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not
	// available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine
	// regions." "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
	Name pulumi.StringOutput `pulumi:"name"`
	// The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during
	// pipeline creation. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg",
	// "count": "3" }.
	PipelineSources pulumi.StringMapOutput `pulumi:"pipelineSources"`
	Project         pulumi.StringOutput    `pulumi:"project"`
	// A reference to the region
	Region pulumi.StringPtrOutput `pulumi:"region"`
	// Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the
	// schedule. If not, users are responsible for creating jobs externally.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
	ScheduleInfo DataPipelinePipelineScheduleInfoPtrOutput `pulumi:"scheduleInfo"`
	// Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine
	// service account will be used.
	SchedulerServiceAccountEmail pulumi.StringOutput `pulumi:"schedulerServiceAccountEmail"`
	// The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State
	// changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through
	// pipelines.patch requests.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state Possible
	// values: ["STATE_UNSPECIFIED", "STATE_RESUMING", "STATE_ACTIVE", "STATE_STOPPING", "STATE_ARCHIVED", "STATE_PAUSED"]
	State    pulumi.StringOutput                   `pulumi:"state"`
	Timeouts DataPipelinePipelineTimeoutsPtrOutput `pulumi:"timeouts"`
	// The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the
	// pipeline.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
	// Possible values: ["PIPELINE_TYPE_UNSPECIFIED", "PIPELINE_TYPE_BATCH", "PIPELINE_TYPE_STREAMING"]
	Type pulumi.StringOutput `pulumi:"type"`
	// Workload information for creating new jobs.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
	Workload DataPipelinePipelineWorkloadPtrOutput `pulumi:"workload"`
}

// NewDataPipelinePipeline registers a new resource with the given unique name, arguments, and options.
func NewDataPipelinePipeline(ctx *pulumi.Context,
	name string, args *DataPipelinePipelineArgs, opts ...pulumi.ResourceOption) (*DataPipelinePipeline, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.State == nil {
		return nil, errors.New("invalid value for required argument 'State'")
	}
	if args.Type == nil {
		return nil, errors.New("invalid value for required argument 'Type'")
	}
	opts = internal.PkgResourceDefaultOpts(opts)
	ref, err := internal.PkgGetPackageRef(ctx)
	if err != nil {
		return nil, err
	}
	var resource DataPipelinePipeline
	err = ctx.RegisterPackageResource("google-beta:index/dataPipelinePipeline:DataPipelinePipeline", name, args, &resource, ref, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetDataPipelinePipeline gets an existing DataPipelinePipeline resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetDataPipelinePipeline(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *DataPipelinePipelineState, opts ...pulumi.ResourceOption) (*DataPipelinePipeline, error) {
	var resource DataPipelinePipeline
	ref, err := internal.PkgGetPackageRef(ctx)
	if err != nil {
		return nil, err
	}
	err = ctx.ReadPackageResource("google-beta:index/dataPipelinePipeline:DataPipelinePipeline", name, id, state, &resource, ref, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering DataPipelinePipeline resources.
type dataPipelinePipelineState struct {
	// The timestamp when the pipeline was initially created. Set by the Data Pipelines service. A timestamp in RFC3339 UTC
	// "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and
	// "2014-10-02T15:01:23.045123456Z".
	CreateTime             *string `pulumi:"createTime"`
	DataPipelinePipelineId *string `pulumi:"dataPipelinePipelineId"`
	// The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores
	// (_).
	DisplayName *string `pulumi:"displayName"`
	// Number of jobs.
	JobCount *float64 `pulumi:"jobCount"`
	// The timestamp when the pipeline was last modified. Set by the Data Pipelines service. A timestamp in RFC3339 UTC "Zulu"
	// format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and
	// "2014-10-02T15:01:23.045123456Z".
	LastUpdateTime *string `pulumi:"lastUpdateTime"`
	// "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID." "- PROJECT_ID can
	// contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see
	// Identifying projects." "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can
	// be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not
	// available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine
	// regions." "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
	Name *string `pulumi:"name"`
	// The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during
	// pipeline creation. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg",
	// "count": "3" }.
	PipelineSources map[string]string `pulumi:"pipelineSources"`
	Project         *string           `pulumi:"project"`
	// A reference to the region
	Region *string `pulumi:"region"`
	// Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the
	// schedule. If not, users are responsible for creating jobs externally.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
	ScheduleInfo *DataPipelinePipelineScheduleInfo `pulumi:"scheduleInfo"`
	// Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine
	// service account will be used.
	SchedulerServiceAccountEmail *string `pulumi:"schedulerServiceAccountEmail"`
	// The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State
	// changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through
	// pipelines.patch requests.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state Possible
	// values: ["STATE_UNSPECIFIED", "STATE_RESUMING", "STATE_ACTIVE", "STATE_STOPPING", "STATE_ARCHIVED", "STATE_PAUSED"]
	State    *string                       `pulumi:"state"`
	Timeouts *DataPipelinePipelineTimeouts `pulumi:"timeouts"`
	// The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the
	// pipeline.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
	// Possible values: ["PIPELINE_TYPE_UNSPECIFIED", "PIPELINE_TYPE_BATCH", "PIPELINE_TYPE_STREAMING"]
	Type *string `pulumi:"type"`
	// Workload information for creating new jobs.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
	Workload *DataPipelinePipelineWorkload `pulumi:"workload"`
}

type DataPipelinePipelineState struct {
	// The timestamp when the pipeline was initially created. Set by the Data Pipelines service. A timestamp in RFC3339 UTC
	// "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and
	// "2014-10-02T15:01:23.045123456Z".
	CreateTime             pulumi.StringPtrInput
	DataPipelinePipelineId pulumi.StringPtrInput
	// The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores
	// (_).
	DisplayName pulumi.StringPtrInput
	// Number of jobs.
	JobCount pulumi.Float64PtrInput
	// The timestamp when the pipeline was last modified. Set by the Data Pipelines service. A timestamp in RFC3339 UTC "Zulu"
	// format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and
	// "2014-10-02T15:01:23.045123456Z".
	LastUpdateTime pulumi.StringPtrInput
	// "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID." "- PROJECT_ID can
	// contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see
	// Identifying projects." "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can
	// be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not
	// available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine
	// regions." "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
	Name pulumi.StringPtrInput
	// The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during
	// pipeline creation. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg",
	// "count": "3" }.
	PipelineSources pulumi.StringMapInput
	Project         pulumi.StringPtrInput
	// A reference to the region
	Region pulumi.StringPtrInput
	// Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the
	// schedule. If not, users are responsible for creating jobs externally.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
	ScheduleInfo DataPipelinePipelineScheduleInfoPtrInput
	// Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine
	// service account will be used.
	SchedulerServiceAccountEmail pulumi.StringPtrInput
	// The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State
	// changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through
	// pipelines.patch requests.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state Possible
	// values: ["STATE_UNSPECIFIED", "STATE_RESUMING", "STATE_ACTIVE", "STATE_STOPPING", "STATE_ARCHIVED", "STATE_PAUSED"]
	State    pulumi.StringPtrInput
	Timeouts DataPipelinePipelineTimeoutsPtrInput
	// The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the
	// pipeline.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
	// Possible values: ["PIPELINE_TYPE_UNSPECIFIED", "PIPELINE_TYPE_BATCH", "PIPELINE_TYPE_STREAMING"]
	Type pulumi.StringPtrInput
	// Workload information for creating new jobs.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
	Workload DataPipelinePipelineWorkloadPtrInput
}

func (DataPipelinePipelineState) ElementType() reflect.Type {
	return reflect.TypeOf((*dataPipelinePipelineState)(nil)).Elem()
}

type dataPipelinePipelineArgs struct {
	DataPipelinePipelineId *string `pulumi:"dataPipelinePipelineId"`
	// The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores
	// (_).
	DisplayName *string `pulumi:"displayName"`
	// "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID." "- PROJECT_ID can
	// contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see
	// Identifying projects." "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can
	// be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not
	// available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine
	// regions." "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
	Name *string `pulumi:"name"`
	// The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during
	// pipeline creation. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg",
	// "count": "3" }.
	PipelineSources map[string]string `pulumi:"pipelineSources"`
	Project         *string           `pulumi:"project"`
	// A reference to the region
	Region *string `pulumi:"region"`
	// Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the
	// schedule. If not, users are responsible for creating jobs externally.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
	ScheduleInfo *DataPipelinePipelineScheduleInfo `pulumi:"scheduleInfo"`
	// Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine
	// service account will be used.
	SchedulerServiceAccountEmail *string `pulumi:"schedulerServiceAccountEmail"`
	// The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State
	// changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through
	// pipelines.patch requests.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state Possible
	// values: ["STATE_UNSPECIFIED", "STATE_RESUMING", "STATE_ACTIVE", "STATE_STOPPING", "STATE_ARCHIVED", "STATE_PAUSED"]
	State    string                        `pulumi:"state"`
	Timeouts *DataPipelinePipelineTimeouts `pulumi:"timeouts"`
	// The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the
	// pipeline.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
	// Possible values: ["PIPELINE_TYPE_UNSPECIFIED", "PIPELINE_TYPE_BATCH", "PIPELINE_TYPE_STREAMING"]
	Type string `pulumi:"type"`
	// Workload information for creating new jobs.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
	Workload *DataPipelinePipelineWorkload `pulumi:"workload"`
}

// The set of arguments for constructing a DataPipelinePipeline resource.
type DataPipelinePipelineArgs struct {
	DataPipelinePipelineId pulumi.StringPtrInput
	// The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores
	// (_).
	DisplayName pulumi.StringPtrInput
	// "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID." "- PROJECT_ID can
	// contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see
	// Identifying projects." "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can
	// be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not
	// available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine
	// regions." "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
	Name pulumi.StringPtrInput
	// The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during
	// pipeline creation. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg",
	// "count": "3" }.
	PipelineSources pulumi.StringMapInput
	Project         pulumi.StringPtrInput
	// A reference to the region
	Region pulumi.StringPtrInput
	// Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the
	// schedule. If not, users are responsible for creating jobs externally.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
	ScheduleInfo DataPipelinePipelineScheduleInfoPtrInput
	// Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine
	// service account will be used.
	SchedulerServiceAccountEmail pulumi.StringPtrInput
	// The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State
	// changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through
	// pipelines.patch requests.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state Possible
	// values: ["STATE_UNSPECIFIED", "STATE_RESUMING", "STATE_ACTIVE", "STATE_STOPPING", "STATE_ARCHIVED", "STATE_PAUSED"]
	State    pulumi.StringInput
	Timeouts DataPipelinePipelineTimeoutsPtrInput
	// The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the
	// pipeline.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
	// Possible values: ["PIPELINE_TYPE_UNSPECIFIED", "PIPELINE_TYPE_BATCH", "PIPELINE_TYPE_STREAMING"]
	Type pulumi.StringInput
	// Workload information for creating new jobs.
	// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
	Workload DataPipelinePipelineWorkloadPtrInput
}

func (DataPipelinePipelineArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*dataPipelinePipelineArgs)(nil)).Elem()
}

type DataPipelinePipelineInput interface {
	pulumi.Input

	ToDataPipelinePipelineOutput() DataPipelinePipelineOutput
	ToDataPipelinePipelineOutputWithContext(ctx context.Context) DataPipelinePipelineOutput
}

func (*DataPipelinePipeline) ElementType() reflect.Type {
	return reflect.TypeOf((**DataPipelinePipeline)(nil)).Elem()
}

func (i *DataPipelinePipeline) ToDataPipelinePipelineOutput() DataPipelinePipelineOutput {
	return i.ToDataPipelinePipelineOutputWithContext(context.Background())
}

func (i *DataPipelinePipeline) ToDataPipelinePipelineOutputWithContext(ctx context.Context) DataPipelinePipelineOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DataPipelinePipelineOutput)
}

type DataPipelinePipelineOutput struct{ *pulumi.OutputState }

func (DataPipelinePipelineOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**DataPipelinePipeline)(nil)).Elem()
}

func (o DataPipelinePipelineOutput) ToDataPipelinePipelineOutput() DataPipelinePipelineOutput {
	return o
}

func (o DataPipelinePipelineOutput) ToDataPipelinePipelineOutputWithContext(ctx context.Context) DataPipelinePipelineOutput {
	return o
}

// The timestamp when the pipeline was initially created. Set by the Data Pipelines service. A timestamp in RFC3339 UTC
// "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and
// "2014-10-02T15:01:23.045123456Z".
func (o DataPipelinePipelineOutput) CreateTime() pulumi.StringOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) pulumi.StringOutput { return v.CreateTime }).(pulumi.StringOutput)
}

func (o DataPipelinePipelineOutput) DataPipelinePipelineId() pulumi.StringOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) pulumi.StringOutput { return v.DataPipelinePipelineId }).(pulumi.StringOutput)
}

// The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores
// (_).
func (o DataPipelinePipelineOutput) DisplayName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) pulumi.StringPtrOutput { return v.DisplayName }).(pulumi.StringPtrOutput)
}

// Number of jobs.
func (o DataPipelinePipelineOutput) JobCount() pulumi.Float64Output {
	return o.ApplyT(func(v *DataPipelinePipeline) pulumi.Float64Output { return v.JobCount }).(pulumi.Float64Output)
}

// The timestamp when the pipeline was last modified. Set by the Data Pipelines service. A timestamp in RFC3339 UTC "Zulu"
// format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and
// "2014-10-02T15:01:23.045123456Z".
func (o DataPipelinePipelineOutput) LastUpdateTime() pulumi.StringOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) pulumi.StringOutput { return v.LastUpdateTime }).(pulumi.StringOutput)
}

// "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID." "- PROJECT_ID can
// contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see
// Identifying projects." "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can
// be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not
// available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine
// regions." "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
func (o DataPipelinePipelineOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

// The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during
// pipeline creation. An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg",
// "count": "3" }.
func (o DataPipelinePipelineOutput) PipelineSources() pulumi.StringMapOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) pulumi.StringMapOutput { return v.PipelineSources }).(pulumi.StringMapOutput)
}

func (o DataPipelinePipelineOutput) Project() pulumi.StringOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) pulumi.StringOutput { return v.Project }).(pulumi.StringOutput)
}

// A reference to the region
func (o DataPipelinePipelineOutput) Region() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) pulumi.StringPtrOutput { return v.Region }).(pulumi.StringPtrOutput)
}

// Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the
// schedule. If not, users are responsible for creating jobs externally.
// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
func (o DataPipelinePipelineOutput) ScheduleInfo() DataPipelinePipelineScheduleInfoPtrOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) DataPipelinePipelineScheduleInfoPtrOutput { return v.ScheduleInfo }).(DataPipelinePipelineScheduleInfoPtrOutput)
}

// Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine
// service account will be used.
func (o DataPipelinePipelineOutput) SchedulerServiceAccountEmail() pulumi.StringOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) pulumi.StringOutput { return v.SchedulerServiceAccountEmail }).(pulumi.StringOutput)
}

// The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State
// changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through
// pipelines.patch requests.
// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state Possible
// values: ["STATE_UNSPECIFIED", "STATE_RESUMING", "STATE_ACTIVE", "STATE_STOPPING", "STATE_ARCHIVED", "STATE_PAUSED"]
func (o DataPipelinePipelineOutput) State() pulumi.StringOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) pulumi.StringOutput { return v.State }).(pulumi.StringOutput)
}

func (o DataPipelinePipelineOutput) Timeouts() DataPipelinePipelineTimeoutsPtrOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) DataPipelinePipelineTimeoutsPtrOutput { return v.Timeouts }).(DataPipelinePipelineTimeoutsPtrOutput)
}

// The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the
// pipeline.
// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
// Possible values: ["PIPELINE_TYPE_UNSPECIFIED", "PIPELINE_TYPE_BATCH", "PIPELINE_TYPE_STREAMING"]
func (o DataPipelinePipelineOutput) Type() pulumi.StringOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) pulumi.StringOutput { return v.Type }).(pulumi.StringOutput)
}

// Workload information for creating new jobs.
// https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
func (o DataPipelinePipelineOutput) Workload() DataPipelinePipelineWorkloadPtrOutput {
	return o.ApplyT(func(v *DataPipelinePipeline) DataPipelinePipelineWorkloadPtrOutput { return v.Workload }).(DataPipelinePipelineWorkloadPtrOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*DataPipelinePipelineInput)(nil)).Elem(), &DataPipelinePipeline{})
	pulumi.RegisterOutputType(DataPipelinePipelineOutput{})
}
